{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ad13b233-e673-41b7-ad77-3799dd4190d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectorMixin\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "5a6d120d-a608-42f5-88b3-eea7454ff15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation feature importance\n",
    "\n",
    "#rozdzielić feature engineering\n",
    "#dodać filtrowanie po korelacji dla numerycznych (min wywalić) (#demonstracje/a dla danych regresyjnych w pliku teoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "50c8822c-e9f8-4655-9464-27c4c9e1eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pobieranie CZĘŚCIOWO WYCZYSZCZONYCH danych\n",
    "\n",
    "train_path = r\"C:\\Users\\weron\\Studia\\Semestr 5\\Fakultet biblioteki Pythona\\Projekt\\data\\house-prices-advanced-regression-techniques\\train_postprocessed.csv\"\n",
    "test_path = r\"C:\\Users\\weron\\Studia\\Semestr 5\\Fakultet biblioteki Pythona\\Projekt\\data\\house-prices-advanced-regression-techniques\\test_postprocessed.csv\"\n",
    "\n",
    "train_og = pd.read_csv(train_path)\n",
    "test_og = pd.read_csv(test_path)\n",
    "\n",
    "train = train_og.copy()\n",
    "test = test_og.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "202c9372-007c-4983-875e-d88b4614cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(train[\"SalePrice\"])\n",
    "X = train.drop(columns=[\"SalePrice\", \"Id\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_test = test.drop(columns=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "b7d07e8a-827f-4f52-b127-ad48733d2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowujemy preprocessing \n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "#tutaj tak naprawdę simpleimputer nie jest potrzebny, do wczytywane dane mają braki 'obrobione' (plik data.py)\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "]) \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "        ('cat', cat_pipeline, make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    remainder='passthrough', #dodatkowo dodane, tak naprawdę nie mamy kolumn poza num i cat, więc ten krok można pominąć\n",
    "    verbose_feature_names_out=False #skracanie nowych nazw kolumn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "74b45018-979b-4c04-9758-815bd7179339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Przygotowanie kroków Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "2113dc89-c6c3-49fd-bedc-47a5a4a9483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie pustych kolumn - doczyszczanie\n",
    "\n",
    "class DropEmptyColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_threshold = 0.9):\n",
    "        self.drop_threshold = drop_threshold \n",
    "        self.cols_to_drop = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.cols_to_drop = X.columns[(X.isna().mean() > self.drop_threshold) |\n",
    "                                      ((X.select_dtypes(include=['int64', 'float64']) == 0).mean() > self.drop_threshold)]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        X = X.drop(columns=self.cols_to_drop, errors='ignore')\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "53be8bf9-4d26-4fe6-a5f2-8154f7a7749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrowanie po korelacji DLA NUMERYCZNYCH\n",
    "\n",
    "class CorrelationFiltering(BaseEstimator, SelectorMixin):\n",
    "    def __init__(self, threshold=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.correlations_ = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise ValueError(\"y nie może być None dla CorrelationFiltering\")\n",
    "        \n",
    "        self.is_dataframe_ = isinstance(X, pd.DataFrame)\n",
    "        \n",
    "        if self.is_dataframe_:\n",
    "            self.numeric_cols_ = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            X_numeric = X[self.numeric_cols_]\n",
    "            values = X_numeric.values\n",
    "        else:\n",
    "            values = X\n",
    "            self.numeric_cols_ = None\n",
    "        \n",
    "        y_values = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        y_values = y_values.ravel()\n",
    "        \n",
    "        for i in range(values.shape[1]):\n",
    "            col = values[:, i]\n",
    "            if np.std(col) == 0:\n",
    "                self.correlations_.append(0.0)\n",
    "            else:\n",
    "                corr = np.corrcoef(col, y_values)[0, 1]\n",
    "                self.correlations_.append(0.0 if np.isnan(corr) else corr)\n",
    "        \n",
    "        self.correlations_ = np.array(self.correlations_)\n",
    "        self.n_features_in_ = len(self.numeric_cols_) if self.is_dataframe_ else values.shape[1]\n",
    "        \n",
    "        if self.is_dataframe_:\n",
    "            self.feature_names_in_ = np.array(self.numeric_cols_)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _get_support_mask(self):\n",
    "        return np.abs(self.correlations_) > self.threshold\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.is_dataframe_:\n",
    "            X = X[self.numeric_cols_]\n",
    "        \n",
    "        mask = self._get_support_mask()\n",
    "        \n",
    "        if self.is_dataframe_:\n",
    "            selected_cols = np.array(self.numeric_cols_)[mask]\n",
    "            return X[selected_cols]\n",
    "        else:\n",
    "            return X[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "cb584145-0617-4763-97ea-8e19b2fabe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logarytmizowanie\n",
    "\n",
    "class Log(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "            \n",
    "        X = X.copy()\n",
    "        \n",
    "        if 'LotArea' in X.columns:\n",
    "            X['log_LotArea'] = np.log1p(X['LotArea'])\n",
    "        if 'LotFrontage' in X.columns:\n",
    "            X['log_LotFrontage'] = np.log1p(X['LotFrontage'])\n",
    "        if 'MasVnrArea' in X.columns:\n",
    "            X['log_MasVnrArea'] = np.log1p(X['MasVnrArea']) #ta cecha dostanie też flagę, bo jest dużo zer \n",
    "\n",
    "        if 'WoodDeckSF' in X.columns:\n",
    "            X['log_WoodDeckSF'] = np.log1p(X['WoodDeckSF']) #ta cecha dostanie też flagę, bo jest dużo zer \n",
    "\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "798bab7f-3b2b-4f82-aa92-5d22faf93302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dodawanie nowych kolumn\n",
    "\n",
    "class AddNewColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):     \n",
    "        X = X.copy()\n",
    "\n",
    "        if 'MasVnrArea' in X.columns:\n",
    "            X['HasMasVnrArea'] = (X['MasVnrArea'] > 0).astype('float64') #flaga\n",
    "\n",
    "        if 'WoodDeckSF' in X.columns:\n",
    "            X['HasWoodDeckSF'] = (X['WoodDeckSF'] > 0).astype('float64') #flaga\n",
    "            \n",
    "        #wiek garażu\n",
    "        if 'GarageYrBlt' in X.columns:\n",
    "            X['GarageAge'] = dt.now().year - X['GarageYrBlt']\n",
    "            X = X.drop(['GarageYrBlt'], axis=1)\n",
    "\n",
    "        #wiek domu od sprzedaży \n",
    "        if all(col in X.columns for col in ['YrSold', 'YearRemodAdd', 'YearBuilt']):\n",
    "            X['AgeAtSold'] = X['YrSold'] - X['YearBuilt']\n",
    "            X['YearsSinceRemod'] = X['YrSold'] - X['YearRemodAdd'] \n",
    "            X['HouseAge'] = dt.now().year - X['YearBuilt']\n",
    "\n",
    "        #sezonowość\n",
    "        if 'MoSold' in X.columns:\n",
    "            X['MoSold_sin'] = np.sin(2 * np.pi * X['MoSold'] / 12)\n",
    "            X['MoSold_cos'] = np.cos(2 * np.pi * X['MoSold'] / 12)\n",
    "            \n",
    "            high_season_months = [4, 5, 6, 7, 8]  \n",
    "            X['HighSeasonSell'] = X['MoSold'].isin(high_season_months).astype('int64')\n",
    "\n",
    "        #interakcja\n",
    "        if 'GrLivArea' in X.columns and 'TotalBsmtSF' in X.columns:\n",
    "            X['GrAndBsmtArea'] = X['GrLivArea'] + X['TotalBsmtSF']\n",
    "\n",
    "        if all(col in X.columns for col in ['FullBath', 'HalfBath', 'BsmtHalfBath', 'BsmtFullBath']):\n",
    "            X['Bathrooms'] = X['FullBath'] + X['BsmtFullBath'] + 0.5*(X['HalfBath'] + X['BsmtHalfBath'])\n",
    "\n",
    "        if all(col in X.columns for col in ['OverallQual', 'OverallCond']):\n",
    "            #X['QualGroup'] = pd.cut(X['OverallQual'], bins=[1,4,6,8,11], labels=['Low','Med','High','VeryHigh'])\n",
    "            #X['CondGroup'] = pd.cut(X['OverallCond'], bins=[1,4,6,8,10], labels=['Low','Med','High','VeryHigh'])\n",
    "            X['QualCondScore'] = X['OverallQual'] * X['OverallCond']\n",
    "       \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "3fd6e3db-6613-4112-a6dc-d0f992ac6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie starych kolumn \n",
    "\n",
    "class DeleteUnnecessaryColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if all(col in X.columns for col in ['HasMasVnrArea', 'MasVnrArea']):\n",
    "            X = X.drop(['MasVnrArea'], axis=1, errors='ignore')\n",
    "        \n",
    "        if all(col in X.columns for col in ['HasWoodDeckSF', 'WoodDeckSF']):\n",
    "            X = X.drop(['WoodDeckSF'], axis=1, errors='ignore')\n",
    "        \n",
    "        if all(col in X.columns for col in ['GarageYrBlt', 'GarageAge']):\n",
    "            X = X.drop(['GarageYrBlt'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Wiek domu od sprzedaży \n",
    "        if all(col in X.columns for col in ['AgeAtSold', 'YearsSinceRemod', 'HouseAge', 'YrSold', 'YearRemodAdd', 'YearBuilt']):\n",
    "            X = X.drop(['YearBuilt', 'YearRemodAdd', 'YrSold'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Sezonowość\n",
    "        if all(col in X.columns for col in ['MoSold', 'HighSeasonSell']):\n",
    "            X = X.drop(['MoSold'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Interakcja\n",
    "        if all(col in X.columns for col in ['GrLivArea', 'TotalBsmtSF', 'GrAndBsmtArea']):\n",
    "            X = X.drop(['TotalBsmtSF'], axis=1, errors='ignore')\n",
    "        \n",
    "        if all(col in X.columns for col in ['Bathrooms', 'FullBath', 'HalfBath', 'BsmtHalfBath', 'BsmtFullBath']):\n",
    "            X = X.drop(['BsmtHalfBath', 'BsmtFullBath', 'FullBath', 'HalfBath'], axis=1, errors='ignore')\n",
    "       \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ecc5f231-5e0d-42d7-8be6-9067b357ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#custom transformer do selekcji cech opartej na feature importance\n",
    "\n",
    "class FeatureImportanceSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.001, n_estimators=100, random_state=42):\n",
    "        self.threshold = threshold\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.feature_mask_ = None\n",
    "        self.feature_importances_ = None\n",
    "        self.n_features_in_ = None\n",
    "        self.n_features_out_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if hasattr(X, 'toarray'): \n",
    "            X = X.toarray()\n",
    "        \n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        #pomocniczy GB model\n",
    "        temp_model = GradientBoostingRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        temp_model.fit(X, y)\n",
    "        \n",
    "        self.feature_importances_ = temp_model.feature_importances_\n",
    "\n",
    "        self.feature_mask_ = self.feature_importances_ >= self.threshold\n",
    "        self.n_features_out_ = self.feature_mask_.sum()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.feature_mask_ is None:\n",
    "            raise ValueError(\"FeatureImportanceSelector must be fitted before transform!\")\n",
    "        \n",
    "        if hasattr(X, 'toarray'):  # sparse matrix\n",
    "            X = X.toarray()\n",
    "        \n",
    "        return X[:, self.feature_mask_]\n",
    "    \n",
    "    def get_selected_features(self, feature_names):\n",
    "        if self.feature_mask_ is None:\n",
    "            raise ValueError(\"FeatureImportanceSelector must be fitted first!\")\n",
    "        \n",
    "        return [name for name, selected in zip(feature_names, self.feature_mask_) if selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "0ac7b7d6-6c30-4743-95a7-1b1325d839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "#bez optymalizacji\n",
    "gb_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "gb_model_del_empty = Pipeline([\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z filtrowaniem po korelacji\n",
    "gb_model_corr = Pipeline([\n",
    "    (\"corr\", CorrelationFiltering()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "gb_model_add = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "gb_model_add_del = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#logarytmizowanie\n",
    "gb_model_log = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#połączenie wszystkich optymalizacji (poza filtrowaniem po korelacji)\n",
    "gb_model_all = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"feature_selection\", FeatureImportanceSelector(threshold=0.00001)), #zamiana kolejności z preprocessorem\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#feature selection\n",
    "gb_model_fis = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"feature_selection\", FeatureImportanceSelector(threshold=0.00001)), #zamiana kolejności z preprocessorem\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "7c557917-1ff9-484e-8091-5196660c6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net\n",
    "\n",
    "#bez optymalizacji\n",
    "enet_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "enet_model_del_empty = Pipeline([\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z filtrowaniem po korelacji\n",
    "enet_model_corr = Pipeline([\n",
    "    (\"corr\", CorrelationFiltering(threshold=0.001)),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "enet_model_add = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "enet_model_add_del = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#logarytmizowanie\n",
    "enet_model_log = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#połączenie wszystkich optymalizacji\n",
    "enet_model_all = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"corr\", CorrelationFiltering()),\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#połączenie tylko log, add\n",
    "enet_model_la = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d81e877e-07b3-4027-b62e-3d2e7f21ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net (liniowy)\n",
    "\n",
    "#bez optymalizacji\n",
    "enet_model.fit(X_train, y_train)\n",
    "pred_enet = enet_model.predict(X_val)\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "enet_model_del_empty.fit(X_train, y_train)\n",
    "pred_enet_del_empty = enet_model_del_empty.predict(X_val)\n",
    "\n",
    "#z filtrowaniem po korelacji\n",
    "enet_model_corr.fit(X_train, y_train)\n",
    "pred_enet_corr = enet_model_corr.predict(X_val)\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "enet_model_add.fit(X_train, y_train)\n",
    "pred_enet_add = enet_model_add.predict(X_val)\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "enet_model_add_del.fit(X_train, y_train)\n",
    "pred_enet_add_del = enet_model_add_del.predict(X_val)\n",
    "\n",
    "#logarytmizowanie\n",
    "enet_model_log.fit(X_train, y_train)\n",
    "pred_enet_log = enet_model_log.predict(X_val)\n",
    "\n",
    "#połączenie wszystkich optymalizacji\n",
    "enet_model_all.fit(X_train, y_train)\n",
    "pred_enet_all = enet_model_all.predict(X_val)\n",
    "\n",
    "#połączenie tylko log, add, drop_empty\n",
    "enet_model_la.fit(X_train, y_train)\n",
    "pred_enet_la = enet_model_la.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3ee40394-8d3b-4227-a517-c6e31f117e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting (drzewiasty)\n",
    "\n",
    "#bez optymalizacji \n",
    "gb_model.fit(X_train, y_train)\n",
    "pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "gb_model_del_empty.fit(X_train, y_train)\n",
    "pred_gb_del_empty = gb_model_del_empty.predict(X_val)\n",
    "\n",
    "\"\"\"#z filtrowaniem po korelacji - NIE DLA DRZEWIASTEGO\n",
    "gb_model_corr.fit(X_train, y_train)\n",
    "pred_gb_corr = gb_model_corr.predict(X_val)\"\"\"\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "gb_model_add.fit(X_train, y_train)\n",
    "pred_gb_add = gb_model_add.predict(X_val)\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "gb_model_add_del.fit(X_train, y_train)\n",
    "pred_gb_add_del = gb_model_add_del.predict(X_val)\n",
    "\n",
    "#logarytmizowanie\n",
    "gb_model_log.fit(X_train, y_train)\n",
    "pred_gb_log = gb_model_log.predict(X_val)\n",
    "\n",
    "#połączenie wszystkich optymalizacji\n",
    "gb_model_all.fit(X_train, y_train)\n",
    "pred_gb_all = gb_model_all.predict(X_val)\n",
    "\n",
    "#fis\n",
    "gb_model_fis.fit(X_train, y_train)\n",
    "pred_gb_fis = gb_model_fis.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "1fd2c078-235f-41ef-b3f0-c7fa0789fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB_add</td>\n",
       "      <td>0.098015</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.890215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENET_log_add</td>\n",
       "      <td>0.098065</td>\n",
       "      <td>0.070804</td>\n",
       "      <td>0.890103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENET_log</td>\n",
       "      <td>0.098198</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.889804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENET_add</td>\n",
       "      <td>0.098881</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.888265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.098935</td>\n",
       "      <td>0.071821</td>\n",
       "      <td>0.888144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENET_drop_empty</td>\n",
       "      <td>0.100740</td>\n",
       "      <td>0.073582</td>\n",
       "      <td>0.884024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENET_all</td>\n",
       "      <td>0.108731</td>\n",
       "      <td>0.080794</td>\n",
       "      <td>0.864896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GB_add_del</td>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.860411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENET_add_del</td>\n",
       "      <td>0.111173</td>\n",
       "      <td>0.076070</td>\n",
       "      <td>0.858759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GB_feature_selection</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.077803</td>\n",
       "      <td>0.857120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB_all</td>\n",
       "      <td>0.112792</td>\n",
       "      <td>0.079103</td>\n",
       "      <td>0.854616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENET_corr</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>0.083453</td>\n",
       "      <td>0.854308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GB_log</td>\n",
       "      <td>0.113297</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>0.853311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.113974</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.851552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GB_drop_empty</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>0.847568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      RMSE       MAE        R2\n",
       "0                 GB_add  0.098015  0.071593  0.890215\n",
       "1           ENET_log_add  0.098065  0.070804  0.890103\n",
       "2               ENET_log  0.098198  0.070974  0.889804\n",
       "3               ENET_add  0.098881  0.071761  0.888265\n",
       "4             ElasticNet  0.098935  0.071821  0.888144\n",
       "5        ENET_drop_empty  0.100740  0.073582  0.884024\n",
       "6               ENET_all  0.108731  0.080794  0.864896\n",
       "7             GB_add_del  0.110521  0.077066  0.860411\n",
       "8           ENET_add_del  0.111173  0.076070  0.858759\n",
       "9   GB_feature_selection  0.111816  0.077803  0.857120\n",
       "10                GB_all  0.112792  0.079103  0.854616\n",
       "11             ENET_corr  0.112911  0.083453  0.854308\n",
       "12                GB_log  0.113297  0.078633  0.853311\n",
       "13     Gradient Boosting  0.113974  0.079202  0.851552\n",
       "14         GB_drop_empty  0.115493  0.079045  0.847568"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Lista modeli i ich predykcji\n",
    "models = ['ElasticNet', 'Gradient Boosting', 'ENET_drop_empty', 'GB_drop_empty', 'ENET_corr',  \n",
    "         'ENET_add', 'GB_add', 'ENET_add_del', 'GB_add_del', 'ENET_log', 'GB_log',\n",
    "         'ENET_all', 'GB_all', 'ENET_log_add', 'GB_feature_selection']\n",
    "predictions = [pred_enet, pred_gb, pred_enet_del_empty, pred_gb_del_empty, pred_enet_corr, \n",
    "              pred_enet_add, pred_enet_add_del, pred_gb_add, pred_gb_add_del, pred_enet_log, pred_gb_log,\n",
    "              pred_enet_all, pred_gb_all, pred_enet_la, pred_gb_fis]\n",
    "\n",
    "# obliczanie metryk\n",
    "results = []\n",
    "for name, pred in zip(models, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    mae = mean_absolute_error(y_val, pred)\n",
    "    r2 = r2_score(y_val, pred)\n",
    "    results.append([name, rmse, mae, r2])\n",
    "\n",
    "# tworzenie DataFrame i sortowanie po R2\n",
    "df_results = pd.DataFrame(results, columns=['Model', 'RMSE', 'MAE', 'R2'])\n",
    "df_results = df_results.sort_values(by='R2', ascending=False).reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b589d864-def0-43c5-b30d-926336dc5620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE_norm</th>\n",
       "      <th>MAE_norm</th>\n",
       "      <th>R2_norm</th>\n",
       "      <th>Combined_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENET_log_add</td>\n",
       "      <td>0.098065</td>\n",
       "      <td>0.070804</td>\n",
       "      <td>0.890103</td>\n",
       "      <td>0.997140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997374</td>\n",
       "      <td>0.998045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENET_log</td>\n",
       "      <td>0.098198</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.889804</td>\n",
       "      <td>0.989522</td>\n",
       "      <td>0.986585</td>\n",
       "      <td>0.990371</td>\n",
       "      <td>0.988811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB_add</td>\n",
       "      <td>0.098015</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENET_add</td>\n",
       "      <td>0.098881</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.888265</td>\n",
       "      <td>0.950417</td>\n",
       "      <td>0.924340</td>\n",
       "      <td>0.954275</td>\n",
       "      <td>0.943366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.098935</td>\n",
       "      <td>0.071821</td>\n",
       "      <td>0.888144</td>\n",
       "      <td>0.947374</td>\n",
       "      <td>0.919619</td>\n",
       "      <td>0.951455</td>\n",
       "      <td>0.939864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENET_drop_empty</td>\n",
       "      <td>0.100740</td>\n",
       "      <td>0.073582</td>\n",
       "      <td>0.884024</td>\n",
       "      <td>0.844074</td>\n",
       "      <td>0.780401</td>\n",
       "      <td>0.854849</td>\n",
       "      <td>0.827127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GB_add_del</td>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.860411</td>\n",
       "      <td>0.284479</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.301142</td>\n",
       "      <td>0.353951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENET_add_del</td>\n",
       "      <td>0.111173</td>\n",
       "      <td>0.076070</td>\n",
       "      <td>0.858759</td>\n",
       "      <td>0.247184</td>\n",
       "      <td>0.583656</td>\n",
       "      <td>0.262417</td>\n",
       "      <td>0.351172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENET_all</td>\n",
       "      <td>0.108731</td>\n",
       "      <td>0.080794</td>\n",
       "      <td>0.864896</td>\n",
       "      <td>0.386902</td>\n",
       "      <td>0.210209</td>\n",
       "      <td>0.406321</td>\n",
       "      <td>0.337778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GB_feature_selection</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.077803</td>\n",
       "      <td>0.857120</td>\n",
       "      <td>0.210382</td>\n",
       "      <td>0.446718</td>\n",
       "      <td>0.223982</td>\n",
       "      <td>0.284003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB_all</td>\n",
       "      <td>0.112792</td>\n",
       "      <td>0.079103</td>\n",
       "      <td>0.854616</td>\n",
       "      <td>0.154577</td>\n",
       "      <td>0.343947</td>\n",
       "      <td>0.165275</td>\n",
       "      <td>0.213527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GB_log</td>\n",
       "      <td>0.113297</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>0.853311</td>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>0.134671</td>\n",
       "      <td>0.204094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.113974</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.851552</td>\n",
       "      <td>0.086919</td>\n",
       "      <td>0.336129</td>\n",
       "      <td>0.093416</td>\n",
       "      <td>0.162982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENET_corr</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>0.083453</td>\n",
       "      <td>0.854308</td>\n",
       "      <td>0.147739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158047</td>\n",
       "      <td>0.105479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GB_drop_empty</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>0.847568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      RMSE       MAE        R2  RMSE_norm  MAE_norm  \\\n",
       "1           ENET_log_add  0.098065  0.070804  0.890103   0.997140  1.000000   \n",
       "2               ENET_log  0.098198  0.070974  0.889804   0.989522  0.986585   \n",
       "0                 GB_add  0.098015  0.071593  0.890215   1.000000  0.937608   \n",
       "3               ENET_add  0.098881  0.071761  0.888265   0.950417  0.924340   \n",
       "4             ElasticNet  0.098935  0.071821  0.888144   0.947374  0.919619   \n",
       "5        ENET_drop_empty  0.100740  0.073582  0.884024   0.844074  0.780401   \n",
       "7             GB_add_del  0.110521  0.077066  0.860411   0.284479  0.504942   \n",
       "8           ENET_add_del  0.111173  0.076070  0.858759   0.247184  0.583656   \n",
       "6               ENET_all  0.108731  0.080794  0.864896   0.386902  0.210209   \n",
       "9   GB_feature_selection  0.111816  0.077803  0.857120   0.210382  0.446718   \n",
       "10                GB_all  0.112792  0.079103  0.854616   0.154577  0.343947   \n",
       "12                GB_log  0.113297  0.078633  0.853311   0.125676  0.381071   \n",
       "13     Gradient Boosting  0.113974  0.079202  0.851552   0.086919  0.336129   \n",
       "11             ENET_corr  0.112911  0.083453  0.854308   0.147739  0.000000   \n",
       "14         GB_drop_empty  0.115493  0.079045  0.847568   0.000000  0.348499   \n",
       "\n",
       "     R2_norm  Combined_Score  \n",
       "1   0.997374        0.998045  \n",
       "2   0.990371        0.988811  \n",
       "0   1.000000        0.981282  \n",
       "3   0.954275        0.943366  \n",
       "4   0.951455        0.939864  \n",
       "5   0.854849        0.827127  \n",
       "7   0.301142        0.353951  \n",
       "8   0.262417        0.351172  \n",
       "6   0.406321        0.337778  \n",
       "9   0.223982        0.284003  \n",
       "10  0.165275        0.213527  \n",
       "12  0.134671        0.204094  \n",
       "13  0.093416        0.162982  \n",
       "11  0.158047        0.105479  \n",
       "14  0.000000        0.104550  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wybór najlepszych pipeline'ów na podstawie metryk\n",
    "\n",
    "#normalizowanie metryk i obliczanie średniej\n",
    "df_results['RMSE_norm'] = (df_results['RMSE'].max() - df_results['RMSE']) / \n",
    "                          (df_results['RMSE'].max() - df_results['RMSE'].min())\n",
    "df_results['MAE_norm'] = (df_results['MAE'].max() - df_results['MAE']) / \n",
    "                         (df_results['MAE'].max() - df_results['MAE'].min())\n",
    "df_results['R2_norm'] = (df_results['R2'] - df_results['R2'].min()) / \n",
    "                        (df_results['R2'].max() - df_results['R2'].min())\n",
    "\n",
    "#średnia ważona\n",
    "df_results['Combined_Score'] = (\n",
    "    0.5 * df_results['RMSE_norm'] +  \n",
    "    0.3 * df_results['MAE_norm'] +   \n",
    "    0.2 * df_results['R2_norm']  \n",
    ")\n",
    "\n",
    "df_results.sort_values('Combined_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe85bbb-f572-4b10-862c-419ce7e067e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2555d-b2f5-4e77-8513-4de8082314ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b12521-5374-4076-92f6-e9e46f1a880d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69988167-b91d-40fd-a184-6235bc80fdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49659cb5-21b7-4f9c-815e-678656866657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
