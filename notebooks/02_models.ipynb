{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e3e8fb1-308c-429f-9327-357d22a68831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../data/processed/train_postprocessed.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test_postprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037a1ea9-c38f-4682-bfd3-2a89b7104f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(train[\"SalePrice\"])\n",
    "X = train.drop(columns=[\"SalePrice\", \"Id\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_test = test.drop(columns=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a27a5a3-7270-4e95-a596-beb007e724b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8a39a2-d0fe-458d-8bea-ae4146d5038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dcf90-6917-4b70-9061-c4cb708c09c6",
   "metadata": {},
   "source": [
    "### Funkcja `rmse_cv` – walidacja krzyżowa\n",
    "\n",
    "W celu rzetelnej oceny jakości modeli regresyjnych zastosowano\n",
    "5-krotną walidację krzyżową (cross-validation).\n",
    "\n",
    "Funkcja `rmse_cv` oblicza średni błąd RMSE (Root Mean Squared Error)\n",
    "uzyskany w kolejnych podziałach danych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f9dba1-dc5f-41ed-8b6f-5db09025a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model, X, y):\n",
    "    scores = -cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=5\n",
    "    )\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c72915-dae9-4ed7-bb56-0df9d36d8cc0",
   "metadata": {},
   "source": [
    "## Model 1: Regresja liniowa (baseline)\n",
    "\n",
    "Regresja liniowa została użyta jako model bazowy (baseline),\n",
    "stanowiący punkt odniesienia dla bardziej zaawansowanych metod.\n",
    "\n",
    "Model ten zakłada:\n",
    "- liniową zależność pomiędzy cechami a zmienną objaśnianą,\n",
    "- brak silnej współliniowości pomiędzy predyktorami.\n",
    "\n",
    "Ze względu na dużą liczbę cech i ich współzależności,\n",
    "oczekuje się, że jego jakość predykcji będzie ograniczona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4aeec14-7a74-4325-896b-e7913890c6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.1183764058176674)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "rmse_lin = rmse_cv(lin_model, X, y)\n",
    "rmse_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933080f-0906-4e29-ba0e-3f7154075f4f",
   "metadata": {},
   "source": [
    "## Model 2: Ridge Regression\n",
    "\n",
    "Ridge Regression jest rozszerzeniem regresji liniowej\n",
    "z regularyzacją typu L2.\n",
    "\n",
    "Zastosowanie kary L2:\n",
    "- zmniejsza wariancję modelu,\n",
    "- ogranicza wpływ współliniowości,\n",
    "- poprawia stabilność predykcji.\n",
    "\n",
    "Model ten jest szczególnie odpowiedni dla danych\n",
    "o dużej liczbie cech, takich jak zbiór Ames Housing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c7fb7a-0a88-4708-bbac-7c514abe349f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10694987120079313)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=10))\n",
    "])\n",
    "\n",
    "rmse_ridge = rmse_cv(ridge_model, X, y)\n",
    "rmse_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370503c9-c74b-4d7a-bf41-83e8711133cd",
   "metadata": {},
   "source": [
    "## Model 3: ElasticNet\n",
    "\n",
    "ElasticNet łączy regularyzację:\n",
    "- L1 (Lasso) – selekcja cech,\n",
    "- L2 (Ridge) – stabilizacja wag.\n",
    "\n",
    "Pozwala to:\n",
    "- automatycznie eliminować mniej istotne zmienne,\n",
    "- zachować odporność na współliniowość.\n",
    "\n",
    "Model ten stanowi kompromis pomiędzy Ridge i Lasso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3074ace-9464-41b3-82bd-206a365ecf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10339412260221055)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "rmse_enet = rmse_cv(enet_model, X, y)\n",
    "rmse_enet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c02a23-ff6a-4950-951a-241ad740a287",
   "metadata": {},
   "source": [
    "## Model 4: Random Forest\n",
    "\n",
    "Random Forest jest zespołem drzew decyzyjnych,\n",
    "uczących się na losowych podpróbkach danych i cech.\n",
    "\n",
    "Zalety:\n",
    "- zdolność modelowania nieliniowości,\n",
    "- odporność na obserwacje odstające,\n",
    "- brak potrzeby skalowania danych.\n",
    "\n",
    "Model ten często osiąga lepsze wyniki niż modele liniowe,\n",
    "kosztem mniejszej interpretowalności.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e1ac01-b1ec-46c4-ade6-3f24f1fc5d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.12574799699617292)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rmse_rf = rmse_cv(rf_model, X, y)\n",
    "rmse_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c75b6a-e99d-4069-a9c0-0141501ab329",
   "metadata": {},
   "source": [
    "## Model 5: Gradient Boosting\n",
    "\n",
    "Gradient Boosting to metoda zespołowa,\n",
    "w której kolejne modele uczą się na błędach poprzednich.\n",
    "\n",
    "Charakterystyka:\n",
    "- wysoka skuteczność predykcyjna,\n",
    "- dobra kontrola nad overfittingiem,\n",
    "- zdolność uchwycenia złożonych zależności.\n",
    "\n",
    "Jest to jeden z najskuteczniejszych modeli\n",
    "dla danych tabelarycznych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b32752-bc8b-4b87-beb0-cf18050d37ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.11233469577987858)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rmse_gb = rmse_cv(gb_model, X, y)\n",
    "rmse_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1919cf-4312-4376-8a3e-9c470843ac97",
   "metadata": {},
   "source": [
    "## Model 6: XGBoost\n",
    "\n",
    "XGBoost jest zaawansowaną implementacją gradient boosting,\n",
    "rozszerzoną m.in. o:\n",
    "- regularyzację,\n",
    "- losowe próbkowanie obserwacji i cech,\n",
    "- optymalizację wydajności obliczeniowej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727c1ca6-a4c5-40f6-9630-2eb0a5b36ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.11197738824304686)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rmse_xgb = rmse_cv(xgb_model, X, y)\n",
    "rmse_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2db7aa-34ef-44e1-b2f7-6bde8fe2ac81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.103394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.106950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.112335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.118376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.125748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      RMSE\n",
       "2         ElasticNet  0.103394\n",
       "1              Ridge  0.106950\n",
       "4  Gradient Boosting  0.112335\n",
       "0  Linear Regression  0.118376\n",
       "3      Random Forest  0.125748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Ridge\",\n",
    "        \"ElasticNet\",\n",
    "        \"Random Forest\",\n",
    "        \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        rmse_lin,\n",
    "        rmse_ridge,\n",
    "        rmse_enet,\n",
    "        rmse_rf,\n",
    "        rmse_gb\n",
    "    ]\n",
    "})\n",
    "\n",
    "results.sort_values(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcb47f-aced-4ede-9ad7-dcd3bdeaf931",
   "metadata": {},
   "source": [
    "## Model 7: Ensemble (model hybrydowy)\n",
    "\n",
    "Ostatnim modelem jest model hybrydowy (ensemble),\n",
    "będący średnią predykcji kilku najlepszych modeli bazowych.\n",
    "\n",
    "Takie podejście pozwala:\n",
    "- zmniejszyć wariancję predykcji,\n",
    "- wykorzystać zalety różnych algorytmów,\n",
    "- uzyskać bardziej stabilne wyniki.\n",
    "\n",
    "Ensemble często przewyższa pojedyncze modele składowe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1cf6346-bf0d-41d0-8b7d-933a8fa04e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.097043</td>\n",
       "      <td>0.069834</td>\n",
       "      <td>0.892381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.099201</td>\n",
       "      <td>0.070536</td>\n",
       "      <td>0.887541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.100410</td>\n",
       "      <td>0.069340</td>\n",
       "      <td>0.884782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.105716</td>\n",
       "      <td>0.074896</td>\n",
       "      <td>0.872286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.111384</td>\n",
       "      <td>0.078077</td>\n",
       "      <td>0.858222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.111824</td>\n",
       "      <td>0.079441</td>\n",
       "      <td>0.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.117059</td>\n",
       "      <td>0.077131</td>\n",
       "      <td>0.843406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      RMSE       MAE        R2\n",
       "0         ElasticNet  0.097043  0.069834  0.892381\n",
       "1              Ridge  0.099201  0.070536  0.887541\n",
       "2           Ensemble  0.100410  0.069340  0.884782\n",
       "3  Linear Regression  0.105716  0.074896  0.872286\n",
       "4  Gradient Boosting  0.111384  0.078077  0.858222\n",
       "5      Random Forest  0.111824  0.079441  0.857100\n",
       "6            XGBoost  0.117059  0.077131  0.843406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "lin_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "enet_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = lin_model.predict(X_val)\n",
    "pred_ridge = ridge_model.predict(X_val)\n",
    "pred_enet = enet_model.predict(X_val)\n",
    "pred_rf = rf_model.predict(X_val)\n",
    "pred_gb = gb_model.predict(X_val)\n",
    "pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "# Ensemble\n",
    "ensemble_pred = ( pred_enet + pred_gb) / 2\n",
    "\n",
    "# Lista modeli i ich predykcji\n",
    "models = ['Linear Regression', 'Ridge', 'ElasticNet', 'Random Forest', \n",
    "          'Gradient Boosting', 'XGBoost', 'Ensemble']\n",
    "predictions = [pred_lr, pred_ridge, pred_enet, pred_rf, pred_gb, pred_xgb, ensemble_pred]\n",
    "\n",
    "# Obliczanie metryk\n",
    "results = []\n",
    "for name, pred in zip(models, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    mae = mean_absolute_error(y_val, pred)\n",
    "    r2 = r2_score(y_val, pred)\n",
    "    results.append([name, rmse, mae, r2])\n",
    "\n",
    "# Tworzenie DataFrame i sortowanie po R2\n",
    "df_results = pd.DataFrame(results, columns=['Model', 'RMSE', 'MAE', 'R2'])\n",
    "df_results = df_results.sort_values(by='R2', ascending=False).reset_index(drop=True)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b5a054-23d0-4f8a-827d-c140769b3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zapis predykcji wszystkich modeli i wartości rzeczywistych\n",
    "\n",
    "output_folder = \"../data/predictions\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "metrics_path = os.path.join(output_folder, \"model_metrics.csv\")\n",
    "df_results.to_csv(metrics_path, index=False)\n",
    "\n",
    "preds_path = os.path.join(output_folder, \"model_predictions.csv\")\n",
    "\n",
    "df_preds = pd.DataFrame({\n",
    "    'y_true': y_val,\n",
    "    'LinearRegression': pred_lr,\n",
    "    'Ridge': pred_ridge,\n",
    "    'ElasticNet': pred_enet,\n",
    "    'RandomForest': pred_rf,\n",
    "    'GradientBoosting': pred_gb,\n",
    "    'XGBoost': pred_xgb,\n",
    "    'Ensemble': ensemble_pred\n",
    "})\n",
    "df_preds.to_csv(preds_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecb822-85cf-43ce-8b15-a632178923dd",
   "metadata": {},
   "source": [
    "### Ważność cech dla modeli drzewiastych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94985e65-b698-46fa-a184-d9599ba21c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Folder na wyniki\n",
    "output_folder = \"../data/predictions\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Funkcja do pobierania nazw cech po preprocessing\n",
    "def get_feature_names(column_transformer):\n",
    "    feature_names = []\n",
    "    for name, transformer, columns in column_transformer.transformers_:\n",
    "        if transformer == 'drop':\n",
    "            continue\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            feature_names.extend(transformer.get_feature_names_out(columns))\n",
    "        else:\n",
    "            feature_names.extend(columns)\n",
    "    return feature_names\n",
    "\n",
    "# Modele drzewiaste w pipeline\n",
    "tree_models = {\n",
    "    \"RandomForest\": rf_model,\n",
    "    \"GradientBoosting\": gb_model,\n",
    "    \"XGBoost\": xgb_model\n",
    "}\n",
    "\n",
    "for model_name, pipeline in tree_models.items():\n",
    "\n",
    "    preprocessor = pipeline.named_steps['prep']\n",
    "    model = pipeline.named_steps['model']\n",
    "\n",
    "    # Sprawdzenie czy model ma feature_importances_\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        continue\n",
    "\n",
    "    # Nazwy cech\n",
    "    feature_names = get_feature_names(preprocessor)\n",
    "\n",
    "    # DataFrame z ważnością cech\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Zapis do CSV\n",
    "    fi_path = os.path.join(output_folder, f\"{model_name}_feature_importance.csv\")\n",
    "    fi_df.to_csv(fi_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baecb03-c930-467a-8e03-277d7957e312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
