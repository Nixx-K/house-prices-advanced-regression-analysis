{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad13b233-e673-41b7-ad77-3799dd4190d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectorMixin\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a6d120d-a608-42f5-88b3-eea7454ff15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation feature importance\n",
    "\n",
    "#rozdzielić feature engineering\n",
    "#dodać filtrowanie po korelacji dla numerycznych (min wywalić) (#demonstracje/a dla danych regresyjnych w pliku teoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50c8822c-e9f8-4655-9464-27c4c9e1eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pobieranie CZĘŚCIOWO WYCZYSZCZONYCH danych\n",
    "\n",
    "train_og = pd.read_csv(\"../data/processed/train_postprocessed.csv\")\n",
    "test_og =pd.read_csv(\"../data/processed/test_postprocessed.csv\")\n",
    "\n",
    "train = train_og.copy()\n",
    "test = test_og.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "202c9372-007c-4983-875e-d88b4614cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(train[\"SalePrice\"])\n",
    "X = train.drop(columns=[\"SalePrice\", \"Id\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_test = test.drop(columns=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7d07e8a-827f-4f52-b127-ad48733d2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowujemy preprocessing \n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "#tutaj tak naprawdę simpleimputer nie jest potrzebny, do wczytywane dane mają braki 'obrobione' (plik data.py)\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "]) \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "        ('cat', cat_pipeline, make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    remainder='passthrough', #dodatkowo dodane, tak naprawdę nie mamy kolumn poza num i cat, więc ten krok można pominąć\n",
    "    verbose_feature_names_out=False #skracanie nowych nazw kolumn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74b45018-979b-4c04-9758-815bd7179339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Przygotowanie kroków Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2113dc89-c6c3-49fd-bedc-47a5a4a9483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie pustych kolumn - doczyszczanie\n",
    "\n",
    "class DropEmptyColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_threshold = 0.9):\n",
    "        self.drop_threshold = drop_threshold \n",
    "        self.cols_to_drop = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.cols_to_drop = X.columns[(X.isna().mean() > self.drop_threshold) |\n",
    "                                      ((X.select_dtypes(include=['int64', 'float64']) == 0).mean() > self.drop_threshold)]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        X = X.drop(columns=self.cols_to_drop, errors='ignore')\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53be8bf9-4d26-4fe6-a5f2-8154f7a7749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrowanie po korelacji DLA NUMERYCZNYCH\n",
    "\n",
    "class CorrelationFiltering(BaseEstimator, SelectorMixin):\n",
    "    def __init__(self, threshold=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.correlations_ = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise ValueError(\"y nie może być None dla CorrelationFiltering\")\n",
    "        \n",
    "        self.is_dataframe_ = isinstance(X, pd.DataFrame)\n",
    "        \n",
    "        if self.is_dataframe_:\n",
    "            self.numeric_cols_ = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            X_numeric = X[self.numeric_cols_]\n",
    "            values = X_numeric.values\n",
    "        else:\n",
    "            values = X\n",
    "            self.numeric_cols_ = None\n",
    "        \n",
    "        y_values = y.values if hasattr(y, 'values') else np.array(y)\n",
    "        y_values = y_values.ravel()\n",
    "        \n",
    "        for i in range(values.shape[1]):\n",
    "            col = values[:, i]\n",
    "            if np.std(col) == 0:\n",
    "                self.correlations_.append(0.0)\n",
    "            else:\n",
    "                corr = np.corrcoef(col, y_values)[0, 1]\n",
    "                self.correlations_.append(0.0 if np.isnan(corr) else corr)\n",
    "        \n",
    "        self.correlations_ = np.array(self.correlations_)\n",
    "        self.n_features_in_ = len(self.numeric_cols_) if self.is_dataframe_ else values.shape[1]\n",
    "        \n",
    "        if self.is_dataframe_:\n",
    "            self.feature_names_in_ = np.array(self.numeric_cols_)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _get_support_mask(self):\n",
    "        return np.abs(self.correlations_) > self.threshold\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.is_dataframe_:\n",
    "            X = X[self.numeric_cols_]\n",
    "        \n",
    "        mask = self._get_support_mask()\n",
    "        \n",
    "        if self.is_dataframe_:\n",
    "            selected_cols = np.array(self.numeric_cols_)[mask]\n",
    "            return X[selected_cols]\n",
    "        else:\n",
    "            return X[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb584145-0617-4763-97ea-8e19b2fabe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class Log(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if 'LotArea' in X.columns:\n",
    "            X['log_LotArea'] = np.log1p(X['LotArea'])\n",
    "        if 'LotFrontage' in X.columns:\n",
    "            X['log_LotFrontage'] = np.log1p(X['LotFrontage'])\n",
    "        if 'MasVnrArea' in X.columns:\n",
    "            X['log_MasVnrArea'] = np.log1p(X['MasVnrArea'])\n",
    "        if 'WoodDeckSF' in X.columns:\n",
    "            X['log_WoodDeckSF'] = np.log1p(X['WoodDeckSF'])\n",
    "        \n",
    "        return X \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "798bab7f-3b2b-4f82-aa92-5d22faf93302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "class AddNewColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):     \n",
    "        X = X.copy()\n",
    "\n",
    "        if 'MasVnrArea' in X.columns:\n",
    "            X['HasMasVnrArea'] = (X['MasVnrArea'] > 0).astype('float64')\n",
    "\n",
    "        if 'WoodDeckSF' in X.columns:\n",
    "            X['HasWoodDeckSF'] = (X['WoodDeckSF'] > 0).astype('float64')\n",
    "\n",
    "        if 'GarageYrBlt' in X.columns:\n",
    "            X['GarageAge'] = dt.now().year - X['GarageYrBlt']\n",
    "            X = X.drop(['GarageYrBlt'], axis=1)\n",
    "\n",
    "        if all(col in X.columns for col in ['YrSold', 'YearRemodAdd', 'YearBuilt']):\n",
    "            X['AgeAtSold'] = X['YrSold'] - X['YearBuilt']\n",
    "            X['YearsSinceRemod'] = X['YrSold'] - X['YearRemodAdd'] \n",
    "            X['HouseAge'] = dt.now().year - X['YearBuilt']\n",
    "\n",
    "        if 'MoSold' in X.columns:\n",
    "            X['MoSold_sin'] = np.sin(2 * np.pi * X['MoSold'] / 12)\n",
    "            X['MoSold_cos'] = np.cos(2 * np.pi * X['MoSold'] / 12)\n",
    "            \n",
    "            high_season_months = [4, 5, 6, 7, 8]  \n",
    "            X['HighSeasonSell'] = X['MoSold'].isin(high_season_months).astype('int64')\n",
    "\n",
    "        if 'GrLivArea' in X.columns and 'TotalBsmtSF' in X.columns:\n",
    "            X['GrAndBsmtArea'] = X['GrLivArea'] + X['TotalBsmtSF']\n",
    "\n",
    "        if all(col in X.columns for col in ['FullBath', 'HalfBath', 'BsmtHalfBath', 'BsmtFullBath']):\n",
    "            X['Bathrooms'] = X['FullBath'] + X['BsmtFullBath'] + 0.5*(X['HalfBath'] + X['BsmtHalfBath'])\n",
    "\n",
    "        if all(col in X.columns for col in ['OverallQual', 'OverallCond']):\n",
    "            X['QualCondScore'] = X['OverallQual'] * X['OverallCond']\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3fd6e3db-6613-4112-a6dc-d0f992ac6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie starych kolumn \n",
    "\n",
    "class DeleteUnnecessaryColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if all(col in X.columns for col in ['HasMasVnrArea', 'MasVnrArea']):\n",
    "            X = X.drop(['MasVnrArea'], axis=1, errors='ignore')\n",
    "        \n",
    "        if all(col in X.columns for col in ['HasWoodDeckSF', 'WoodDeckSF']):\n",
    "            X = X.drop(['WoodDeckSF'], axis=1, errors='ignore')\n",
    "        \n",
    "        if all(col in X.columns for col in ['GarageYrBlt', 'GarageAge']):\n",
    "            X = X.drop(['GarageYrBlt'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Wiek domu od sprzedaży \n",
    "        if all(col in X.columns for col in ['AgeAtSold', 'YearsSinceRemod', 'HouseAge', 'YrSold', 'YearRemodAdd', 'YearBuilt']):\n",
    "            X = X.drop(['YearBuilt', 'YearRemodAdd', 'YrSold'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Sezonowość\n",
    "        if all(col in X.columns for col in ['MoSold', 'HighSeasonSell']):\n",
    "            X = X.drop(['MoSold'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Interakcja\n",
    "        if all(col in X.columns for col in ['GrLivArea', 'TotalBsmtSF', 'GrAndBsmtArea']):\n",
    "            X = X.drop(['TotalBsmtSF'], axis=1, errors='ignore')\n",
    "        \n",
    "        if all(col in X.columns for col in ['Bathrooms', 'FullBath', 'HalfBath', 'BsmtHalfBath', 'BsmtFullBath']):\n",
    "            X = X.drop(['BsmtHalfBath', 'BsmtFullBath', 'FullBath', 'HalfBath'], axis=1, errors='ignore')\n",
    "       \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ecc5f231-5e0d-42d7-8be6-9067b357ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#custom transformer do selekcji cech opartej na feature importance\n",
    "\n",
    "class FeatureImportanceSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.001, n_estimators=100, random_state=42):\n",
    "        self.threshold = threshold\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.feature_mask_ = None\n",
    "        self.feature_importances_ = None\n",
    "        self.n_features_in_ = None\n",
    "        self.n_features_out_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if hasattr(X, 'toarray'): \n",
    "            X = X.toarray()\n",
    "        \n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        #pomocniczy GB model\n",
    "        temp_model = GradientBoostingRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        temp_model.fit(X, y)\n",
    "        \n",
    "        self.feature_importances_ = temp_model.feature_importances_\n",
    "\n",
    "        self.feature_mask_ = self.feature_importances_ >= self.threshold\n",
    "        self.n_features_out_ = self.feature_mask_.sum()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.feature_mask_ is None:\n",
    "            raise ValueError(\"FeatureImportanceSelector must be fitted before transform!\")\n",
    "        \n",
    "        if hasattr(X, 'toarray'):  # sparse matrix\n",
    "            X = X.toarray()\n",
    "        \n",
    "        return X[:, self.feature_mask_]\n",
    "    \n",
    "    def get_selected_features(self, feature_names):\n",
    "        if self.feature_mask_ is None:\n",
    "            raise ValueError(\"FeatureImportanceSelector must be fitted first!\")\n",
    "        \n",
    "        return [name for name, selected in zip(feature_names, self.feature_mask_) if selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ac7b7d6-6c30-4743-95a7-1b1325d839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "#bez optymalizacji\n",
    "gb_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "gb_model_del_empty = Pipeline([\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z filtrowaniem po korelacji\n",
    "gb_model_corr = Pipeline([\n",
    "    (\"corr\", CorrelationFiltering()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "gb_model_add = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "gb_model_add_del = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#logarytmizowanie\n",
    "gb_model_log = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#połączenie wszystkich optymalizacji (poza filtrowaniem po korelacji)\n",
    "gb_model_all = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"feature_selection\", FeatureImportanceSelector(threshold=0.00001)), #zamiana kolejności z preprocessorem\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#feature selection\n",
    "gb_model_fis = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"feature_selection\", FeatureImportanceSelector(threshold=0.00001)), #zamiana kolejności z preprocessorem\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c557917-1ff9-484e-8091-5196660c6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net\n",
    "\n",
    "#bez optymalizacji\n",
    "enet_model = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "enet_model_del_empty = Pipeline([\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z filtrowaniem po korelacji\n",
    "enet_model_corr = Pipeline([\n",
    "    (\"corr\", CorrelationFiltering(threshold=0.001)),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "enet_model_add = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "enet_model_add_del = Pipeline([\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#logarytmizowanie\n",
    "enet_model_log = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#połączenie wszystkich optymalizacji\n",
    "enet_model_all = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"del\", DeleteUnnecessaryColumns()),\n",
    "    (\"corr\", CorrelationFiltering()),\n",
    "    (\"del_empty\", DropEmptyColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])\n",
    "\n",
    "#połączenie tylko log, add\n",
    "enet_model_la = Pipeline([\n",
    "    (\"log\", Log()),\n",
    "    (\"add\", AddNewColumns()),\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d81e877e-07b3-4027-b62e-3d2e7f21ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net (liniowy)\n",
    "\n",
    "#bez optymalizacji\n",
    "enet_model.fit(X_train, y_train)\n",
    "pred_enet = enet_model.predict(X_val)\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "enet_model_del_empty.fit(X_train, y_train)\n",
    "pred_enet_del_empty = enet_model_del_empty.predict(X_val)\n",
    "\n",
    "#z filtrowaniem po korelacji\n",
    "enet_model_corr.fit(X_train, y_train)\n",
    "pred_enet_corr = enet_model_corr.predict(X_val)\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "enet_model_add.fit(X_train, y_train)\n",
    "pred_enet_add = enet_model_add.predict(X_val)\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "enet_model_add_del.fit(X_train, y_train)\n",
    "pred_enet_add_del = enet_model_add_del.predict(X_val)\n",
    "\n",
    "#logarytmizowanie\n",
    "enet_model_log.fit(X_train, y_train)\n",
    "pred_enet_log = enet_model_log.predict(X_val)\n",
    "\n",
    "#połączenie wszystkich optymalizacji\n",
    "enet_model_all.fit(X_train, y_train)\n",
    "pred_enet_all = enet_model_all.predict(X_val)\n",
    "\n",
    "#połączenie tylko log, add, drop_empty\n",
    "enet_model_la.fit(X_train, y_train)\n",
    "pred_enet_la = enet_model_la.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ee40394-8d3b-4227-a517-c6e31f117e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting (drzewiasty)\n",
    "\n",
    "#bez optymalizacji \n",
    "gb_model.fit(X_train, y_train)\n",
    "pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "#z usuwaniem pustych kolumn\n",
    "gb_model_del_empty.fit(X_train, y_train)\n",
    "pred_gb_del_empty = gb_model_del_empty.predict(X_val)\n",
    "\n",
    "\"\"\"#z filtrowaniem po korelacji - NIE DLA DRZEWIASTEGO\n",
    "gb_model_corr.fit(X_train, y_train)\n",
    "pred_gb_corr = gb_model_corr.predict(X_val)\"\"\"\n",
    "\n",
    "#z dodawaniem nowych kolumn\n",
    "gb_model_add.fit(X_train, y_train)\n",
    "pred_gb_add = gb_model_add.predict(X_val)\n",
    "\n",
    "#z dodawaniem nowych i dropnięciem starych\n",
    "gb_model_add_del.fit(X_train, y_train)\n",
    "pred_gb_add_del = gb_model_add_del.predict(X_val)\n",
    "\n",
    "#logarytmizowanie\n",
    "gb_model_log.fit(X_train, y_train)\n",
    "pred_gb_log = gb_model_log.predict(X_val)\n",
    "\n",
    "#połączenie wszystkich optymalizacji\n",
    "gb_model_all.fit(X_train, y_train)\n",
    "pred_gb_all = gb_model_all.predict(X_val)\n",
    "\n",
    "#fis\n",
    "gb_model_fis.fit(X_train, y_train)\n",
    "pred_gb_fis = gb_model_fis.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fd2c078-235f-41ef-b3f0-c7fa0789fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB_add</td>\n",
       "      <td>0.098015</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.890215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENET_log_add</td>\n",
       "      <td>0.098065</td>\n",
       "      <td>0.070804</td>\n",
       "      <td>0.890103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENET_log</td>\n",
       "      <td>0.098198</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.889804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENET_add</td>\n",
       "      <td>0.098881</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.888265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.098935</td>\n",
       "      <td>0.071821</td>\n",
       "      <td>0.888144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENET_drop_empty</td>\n",
       "      <td>0.100740</td>\n",
       "      <td>0.073582</td>\n",
       "      <td>0.884024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENET_all</td>\n",
       "      <td>0.108731</td>\n",
       "      <td>0.080794</td>\n",
       "      <td>0.864896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GB_add_del</td>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.860411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENET_add_del</td>\n",
       "      <td>0.111173</td>\n",
       "      <td>0.076070</td>\n",
       "      <td>0.858759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GB_feature_selection</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.077803</td>\n",
       "      <td>0.857120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENET_corr</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>0.083453</td>\n",
       "      <td>0.854308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GB_all</td>\n",
       "      <td>0.112924</td>\n",
       "      <td>0.079868</td>\n",
       "      <td>0.854276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GB_log</td>\n",
       "      <td>0.113297</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>0.853311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.113974</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.851552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GB_drop_empty</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>0.847568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      RMSE       MAE        R2\n",
       "0                 GB_add  0.098015  0.071593  0.890215\n",
       "1           ENET_log_add  0.098065  0.070804  0.890103\n",
       "2               ENET_log  0.098198  0.070974  0.889804\n",
       "3               ENET_add  0.098881  0.071761  0.888265\n",
       "4             ElasticNet  0.098935  0.071821  0.888144\n",
       "5        ENET_drop_empty  0.100740  0.073582  0.884024\n",
       "6               ENET_all  0.108731  0.080794  0.864896\n",
       "7             GB_add_del  0.110521  0.077066  0.860411\n",
       "8           ENET_add_del  0.111173  0.076070  0.858759\n",
       "9   GB_feature_selection  0.111816  0.077803  0.857120\n",
       "10             ENET_corr  0.112911  0.083453  0.854308\n",
       "11                GB_all  0.112924  0.079868  0.854276\n",
       "12                GB_log  0.113297  0.078633  0.853311\n",
       "13     Gradient Boosting  0.113974  0.079202  0.851552\n",
       "14         GB_drop_empty  0.115493  0.079045  0.847568"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Lista modeli i ich predykcji\n",
    "models = ['ElasticNet', 'Gradient Boosting', 'ENET_drop_empty', 'GB_drop_empty', 'ENET_corr',  \n",
    "         'ENET_add', 'GB_add', 'ENET_add_del', 'GB_add_del', 'ENET_log', 'GB_log',\n",
    "         'ENET_all', 'GB_all', 'ENET_log_add', 'GB_feature_selection']\n",
    "predictions = [pred_enet, pred_gb, pred_enet_del_empty, pred_gb_del_empty, pred_enet_corr, \n",
    "              pred_enet_add, pred_enet_add_del, pred_gb_add, pred_gb_add_del, pred_enet_log, pred_gb_log,\n",
    "              pred_enet_all, pred_gb_all, pred_enet_la, pred_gb_fis]\n",
    "\n",
    "# obliczanie metryk\n",
    "results = []\n",
    "for name, pred in zip(models, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    mae = mean_absolute_error(y_val, pred)\n",
    "    r2 = r2_score(y_val, pred)\n",
    "    results.append([name, rmse, mae, r2])\n",
    "\n",
    "# tworzenie DataFrame i sortowanie po R2\n",
    "df_results = pd.DataFrame(results, columns=['Model', 'RMSE', 'MAE', 'R2'])\n",
    "df_results = df_results.sort_values(by='R2', ascending=False).reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b589d864-def0-43c5-b30d-926336dc5620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE_norm</th>\n",
       "      <th>MAE_norm</th>\n",
       "      <th>R2_norm</th>\n",
       "      <th>Combined_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENET_log_add</td>\n",
       "      <td>0.098065</td>\n",
       "      <td>0.070804</td>\n",
       "      <td>0.890103</td>\n",
       "      <td>0.997140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997374</td>\n",
       "      <td>0.998045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENET_log</td>\n",
       "      <td>0.098198</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.889804</td>\n",
       "      <td>0.989522</td>\n",
       "      <td>0.986585</td>\n",
       "      <td>0.990371</td>\n",
       "      <td>0.988811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB_add</td>\n",
       "      <td>0.098015</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENET_add</td>\n",
       "      <td>0.098881</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.888265</td>\n",
       "      <td>0.950417</td>\n",
       "      <td>0.924340</td>\n",
       "      <td>0.954275</td>\n",
       "      <td>0.943366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.098935</td>\n",
       "      <td>0.071821</td>\n",
       "      <td>0.888144</td>\n",
       "      <td>0.947374</td>\n",
       "      <td>0.919619</td>\n",
       "      <td>0.951455</td>\n",
       "      <td>0.939864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENET_drop_empty</td>\n",
       "      <td>0.100740</td>\n",
       "      <td>0.073582</td>\n",
       "      <td>0.884024</td>\n",
       "      <td>0.844074</td>\n",
       "      <td>0.780401</td>\n",
       "      <td>0.854849</td>\n",
       "      <td>0.827127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GB_add_del</td>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.860411</td>\n",
       "      <td>0.284479</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.301142</td>\n",
       "      <td>0.353951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENET_add_del</td>\n",
       "      <td>0.111173</td>\n",
       "      <td>0.076070</td>\n",
       "      <td>0.858759</td>\n",
       "      <td>0.247184</td>\n",
       "      <td>0.583656</td>\n",
       "      <td>0.262417</td>\n",
       "      <td>0.351172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENET_all</td>\n",
       "      <td>0.108731</td>\n",
       "      <td>0.080794</td>\n",
       "      <td>0.864896</td>\n",
       "      <td>0.386902</td>\n",
       "      <td>0.210209</td>\n",
       "      <td>0.406321</td>\n",
       "      <td>0.337778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GB_feature_selection</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.077803</td>\n",
       "      <td>0.857120</td>\n",
       "      <td>0.210382</td>\n",
       "      <td>0.446718</td>\n",
       "      <td>0.223982</td>\n",
       "      <td>0.284003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GB_log</td>\n",
       "      <td>0.113297</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>0.853311</td>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>0.134671</td>\n",
       "      <td>0.204094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GB_all</td>\n",
       "      <td>0.112924</td>\n",
       "      <td>0.079868</td>\n",
       "      <td>0.854276</td>\n",
       "      <td>0.147019</td>\n",
       "      <td>0.283450</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>0.190001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.113974</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.851552</td>\n",
       "      <td>0.086919</td>\n",
       "      <td>0.336129</td>\n",
       "      <td>0.093416</td>\n",
       "      <td>0.162982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENET_corr</td>\n",
       "      <td>0.112911</td>\n",
       "      <td>0.083453</td>\n",
       "      <td>0.854308</td>\n",
       "      <td>0.147739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158047</td>\n",
       "      <td>0.105479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GB_drop_empty</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>0.847568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      RMSE       MAE        R2  RMSE_norm  MAE_norm  \\\n",
       "1           ENET_log_add  0.098065  0.070804  0.890103   0.997140  1.000000   \n",
       "2               ENET_log  0.098198  0.070974  0.889804   0.989522  0.986585   \n",
       "0                 GB_add  0.098015  0.071593  0.890215   1.000000  0.937608   \n",
       "3               ENET_add  0.098881  0.071761  0.888265   0.950417  0.924340   \n",
       "4             ElasticNet  0.098935  0.071821  0.888144   0.947374  0.919619   \n",
       "5        ENET_drop_empty  0.100740  0.073582  0.884024   0.844074  0.780401   \n",
       "7             GB_add_del  0.110521  0.077066  0.860411   0.284479  0.504942   \n",
       "8           ENET_add_del  0.111173  0.076070  0.858759   0.247184  0.583656   \n",
       "6               ENET_all  0.108731  0.080794  0.864896   0.386902  0.210209   \n",
       "9   GB_feature_selection  0.111816  0.077803  0.857120   0.210382  0.446718   \n",
       "12                GB_log  0.113297  0.078633  0.853311   0.125676  0.381071   \n",
       "11                GB_all  0.112924  0.079868  0.854276   0.147019  0.283450   \n",
       "13     Gradient Boosting  0.113974  0.079202  0.851552   0.086919  0.336129   \n",
       "10             ENET_corr  0.112911  0.083453  0.854308   0.147739  0.000000   \n",
       "14         GB_drop_empty  0.115493  0.079045  0.847568   0.000000  0.348499   \n",
       "\n",
       "     R2_norm  Combined_Score  \n",
       "1   0.997374        0.998045  \n",
       "2   0.990371        0.988811  \n",
       "0   1.000000        0.981282  \n",
       "3   0.954275        0.943366  \n",
       "4   0.951455        0.939864  \n",
       "5   0.854849        0.827127  \n",
       "7   0.301142        0.353951  \n",
       "8   0.262417        0.351172  \n",
       "6   0.406321        0.337778  \n",
       "9   0.223982        0.284003  \n",
       "12  0.134671        0.204094  \n",
       "11  0.157285        0.190001  \n",
       "13  0.093416        0.162982  \n",
       "10  0.158047        0.105479  \n",
       "14  0.000000        0.104550  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wybór najlepszych pipeline'ów na podstawie metryk\n",
    "\n",
    "#normalizowanie metryk i obliczanie średniej\n",
    "df_results['RMSE_norm'] = (df_results['RMSE'].max() - df_results['RMSE']) / (df_results['RMSE'].max() - df_results['RMSE'].min())\n",
    "df_results['MAE_norm'] = (df_results['MAE'].max() - df_results['MAE']) /  (df_results['MAE'].max() - df_results['MAE'].min())\n",
    "df_results['R2_norm'] = (df_results['R2'] - df_results['R2'].min()) / (df_results['R2'].max() - df_results['R2'].min())\n",
    "\n",
    "#średnia ważona\n",
    "df_results['Combined_Score'] = (\n",
    "    0.5 * df_results['RMSE_norm'] +  \n",
    "    0.3 * df_results['MAE_norm'] +   \n",
    "    0.2 * df_results['R2_norm']  \n",
    ")\n",
    "\n",
    "df_results.sort_values('Combined_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bfe85bbb-f572-4b10-862c-419ce7e067e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_gb_pipeline.pkl']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zapis najlepszych piplienów\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(enet_model_la, \"best_enet_pipeline.pkl\")\n",
    "joblib.dump(gb_model_add, \"best_gb_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b12521-5374-4076-92f6-e9e46f1a880d",
   "metadata": {},
   "source": [
    "# Optymalizacja modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69988167-b91d-40fd-a184-6235bc80fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet BEST params: {'model__alpha': 0.001, 'model__l1_ratio': 0.9}\n",
      "ElasticNet BEST CV RMSE: 0.11038763345351361\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet - regularyzacja i GridSearchCV\n",
    "\n",
    "enet_param_grid = {\n",
    "    \"model__alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"model__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "enet_grid = GridSearchCV(\n",
    "    estimator=enet_model_la,\n",
    "    param_grid=enet_param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "enet_grid.fit(X_train, y_train)\n",
    "\n",
    "best_enet_pipeline = enet_grid.best_estimator_\n",
    "\n",
    "print(\"ElasticNet BEST params:\", enet_grid.best_params_)\n",
    "print(\"ElasticNet BEST CV RMSE:\", -enet_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7440c05-c3e0-4d79-991a-4a7ddff11a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB BEST params: {'model__learning_rate': 0.05, 'model__max_depth': 4, 'model__n_estimators': 500, 'model__subsample': 0.8}\n",
      "GB BEST CV RMSE: 0.11402089405126632\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting - optymailziacja hyperparametrów Grid\n",
    "\n",
    "gb_param_grid = {\n",
    "    \"model__n_estimators\": [200, 300, 500],\n",
    "    \"model__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 4],\n",
    "    \"model__subsample\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    estimator=gb_model_add,\n",
    "    param_grid=gb_param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "best_gb_pipeline = gb_grid.best_estimator_\n",
    "\n",
    "print(\"GB BEST params:\", gb_grid.best_params_)\n",
    "print(\"GB BEST CV RMSE:\", -gb_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "886c3a6e-557c-48f6-b673-5bf5a067a3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Etap</th>\n",
       "      <th>Bazowy (RMSE)</th>\n",
       "      <th>Pipeline (RMSE)</th>\n",
       "      <th>Pipeline + Tuning (RMSE)</th>\n",
       "      <th>Bazowy (R2)</th>\n",
       "      <th>Pipeline (R2)</th>\n",
       "      <th>Pipeline + Tuning (R2)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.892381</td>\n",
       "      <td>0.890103</td>\n",
       "      <td>0.886285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.012406</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.858759</td>\n",
       "      <td>0.861369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Etap              Bazowy (RMSE)  Pipeline (RMSE)  Pipeline + Tuning (RMSE)  \\\n",
       "Model                                                                        \n",
       "ElasticNet             0.009417         0.009617                  0.009951   \n",
       "GradientBoosting       0.012406         0.012359                  0.012131   \n",
       "\n",
       "Etap              Bazowy (R2)  Pipeline (R2)  Pipeline + Tuning (R2)  \n",
       "Model                                                                 \n",
       "ElasticNet           0.892381       0.890103                0.886285  \n",
       "GradientBoosting     0.858222       0.858759                0.861369  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tworzenie tabeli porównawczej\n",
    "\n",
    "preds_path = \"../data/predictions/model_predictions.csv\"\n",
    "df_preds_base = pd.read_csv(preds_path)\n",
    "y_val_array = df_preds_base['y_true'].values\n",
    "\n",
    "def eval_preds(y_true, y_pred, model_name, stage):\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Etap\": stage,\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def eval_model(model, X_train, y_train, X_val, y_val, stage, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Etap\": stage,\n",
    "        \"RMSE\": mean_squared_error(y_val, y_pred_val),\n",
    "        \"R2\": r2_score(y_val, y_pred_val)\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# ElasticNet\n",
    "results.append(eval_preds(y_val_array, df_preds_base['ElasticNet'].values, \"ElasticNet\", \"Bazowy\"))\n",
    "results.append(eval_model(enet_model_la, X_train, y_train, X_val, y_val, \"Pipeline\", \"ElasticNet\"))\n",
    "results.append(eval_model(best_enet_pipeline, X_train, y_train, X_val, y_val, \"Pipeline + Tuning\", \"ElasticNet\"))\n",
    "\n",
    "# GradientBoosting\n",
    "results.append(eval_preds(y_val_array, df_preds_base['GradientBoosting'].values, \"GradientBoosting\", \"Bazowy\"))\n",
    "results.append(eval_model(gb_model_add, X_train, y_train, X_val, y_val, \"Pipeline\", \"GradientBoosting\"))\n",
    "results.append(eval_model(best_gb_pipeline, X_train, y_train, X_val, y_val, \"Pipeline + Tuning\", \"GradientBoosting\"))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_rmse = df_results.pivot(index='Model', columns='Etap', values='RMSE')\n",
    "df_r2 = df_results.pivot(index='Model', columns='Etap', values='R2')\n",
    "\n",
    "df = pd.concat([df_rmse.add_suffix(\" (RMSE)\"), df_r2.add_suffix(\" (R2)\")], axis=1)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "df4fda2a-8685-4d3a-9f88-ad2122fbcb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wykres porównawczy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Kolory: niebieski i pomarańczowy dla etapów\n",
    "palette = [\"#1f77b4\", \"#ff7f0e\", \"#aec7e8\"]  # Bazowy, Pipeline, Pipeline + Tuning\n",
    "\n",
    "# Przygotowanie danych\n",
    "df_plot = df_results.melt(id_vars=['Model', 'Etap'], value_vars=['RMSE', 'R2'], \n",
    "                          var_name='Metric', value_name='Score')\n",
    "\n",
    "# Oddzielne wykresy dla RMSE i R2\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
    "\n",
    "# RMSE\n",
    "sns.barplot(data=df_plot[df_plot['Metric']=='RMSE'], x='Model', y='Score', hue='Etap', palette=palette, ax=axes[0])\n",
    "axes[0].set_title('RMSE modeli')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylim(0.008, None) \n",
    "axes[0].legend(title='Etap', loc='upper right')\n",
    "\n",
    "# R2\n",
    "sns.barplot(data=df_plot[df_plot['Metric']=='R2'], x='Model', y='Score', hue='Etap', palette=palette, ax=axes[1])\n",
    "axes[1].set_title('R² modeli')\n",
    "axes[1].set_ylabel('R²')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].set_ylim(0.84, 0.9) \n",
    "axes[1].legend(title='Etap', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98213aa-bd98-4d7d-afa1-e713392eacf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
